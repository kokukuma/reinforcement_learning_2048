2d_random_walk_mylib
===========================

## 目的
+ 同じ2d-random-walk問題をpybrain, 自作のライブラリ(mylib)それぞれで学習し, 同等の性能が出るか検証する.

## 検証問題.
+ 2次元ランダムウォーク
  + [2d-random-walk-pybrain](docs/2d_random_walk.md)と同じ.

## 検証１
+ 概要
  + pybrainと同条件での検証.

+ モデル
  + 基本的にpybrainで使用されているものと同じ.
  + 使われているパラメータを以下で, 比較する.
  + 学習方法のみ異なる.
    + pybrainではiProp-が使われているが, mylibではbackpropが使われている.
    + それに合わせて, 学習係数/更新方法を変更している.
    + iRprop-の方が収束が速いため, 最大epoch数も変えようかとも思ったが, それは, 検証２に譲った.

    |  分類    |  パラメータ              |     mylib             |      pybrain     |
    |----------|--------------------------|-----------------------|------------------|
    | NN学習   | ネットワーク構造         | 16/16/1               |   同じ           |
    |          | 層の種類                 | linear/sigmoid/linear |   同じ           |
    |          | 学習方法                 | backprop              |   iRprop-        |
    |          | 更新方法                 | mini-batch(size=50)   |   batch          |
    |          | 学習係数                 | 0.05                  |  1.0e-6 - 5.0    |
    |          | sigmoid-alpha            | 1                     |    1             |
    |          | 最大epoch数              | 50                    |   50             |
    |          | 閾値                     | 1                     |    1             |
    |          | 重み初期値               | 平均0, 分散0.01       |    ?             |
    | 強化学習 | 総学習エピソード数       | 100                   |  100             |
    |          | 1学習エピソード数        | 10                    |   10             |
    |          | 同エピソード繰り返し回数 | 1                     |   1              |
    |          | 報酬レンジ               | 0 or 1000             |  0 or 1000       |
    |          | 貪欲係数                 | 0.7                   |  0.7             |
    |          | Q値の学習係数(alpha)     | 0.5                   |  0.5             |
    |          | 割引率(gamma)            | 0.9                   |  0.9             |

+ 評価方法
  + 初期値の影響を考慮し, トレーニングから評価までを50回繰りし平均を取る.
  + 確認する指標
    + ゴール到達割合
    + ゴールまでの平均step数

+ 結果
  + ほぼ同等の結果が得られた.
  + しかし, 最大epoch数50ってのは, iProp-ならともかく, backpropでは小さすぎる木もするが..
  + 訓練データ自体がどんどん変わる(Q値が更新されるから)強化学習だから,
    1回の学習で完全に一致することを目標にしなくてもいいのかな.

  + 平均得点, 平均step

    |     path|       average score|        average step|
    |---------|--------------------|--------------------|
    | pybrain |  1000.00(    0.00) |     6.62(    4.60) |
    |   mylib |  1000.00(    0.00) |     6.82(    3.70) |


## 検証2
+ 概要
  + パラメータや手法を変えて, NNの学習が上手く進むようにする..
    + mini-batch, backprop, 最大epoch数 : 50 (default)
    + mini-batch, backprop, 最大epoch数 : 500(50 batch size)
    + batch,      backprop, 最大epoch数 : 500
    + batch,      iRprop-,  最大epoch数 : 50
    + batch,      iRprop-,  最大epoch数 : 500

  + 訓練データの影響を調べるため, 以下の値も調べた.
    + 訓練データの平均スコア, 平均ステップ
    + NNのトレーニング完了時の残差平方和

+ 結果
  + 平均スコア, 平均step
    + なぜ、rpropが微妙に不安定...誤差の降下速度は確かに速いが.

    |           path|       average score|        average step|
    |---------------|--------------------|--------------------|
    |           base|  1000.00(    0.00) |     6.82(    3.70) |
    | mini-batch-500|   980.00(  140.00) |    12.98(   20.08) |
    |      batch-500|  1000.00(    0.00) |     8.06(    7.26) |
    |       rprop-50|   800.00(  400.00) |    17.92(   27.60) |
    |      rprop-500|   860.00(  346.99) |    20.46(   30.63) |

  + 訓練データと学習完了時の残差平方和
    + 最大epoch回数が多いほど, 誤差が少ない.

    |           path|train data ave-score| train data ave-step| train err| valid err|
    |---------------|--------------------|--------------------|----------|----------|
    |           base|   370.00(  482.80) |    47.50(   33.24) |   240.85 |   354.32 |
    |      batch-500|   470.00(  499.10) |    53.80(   33.20) |    92.95 |   448.08 |
    | mini-batch-500|   580.00(  493.56) |    52.41(   32.75) |   185.25 |   250.69 |
    |       rprop-50|   470.00(  499.10) |    46.61(   34.74) |   367.97 |   465.59 |
    |      rprop-500|   560.00(  496.39) |    50.29(   35.33) |   143.25 |   417.27 |


## 検証3
+ 概要
  + 総学習エピソード数/1学習のエピソード数を変更した場合の変化を確認.
  + 変更したパラメータ
    + 総学習エピソード数  : 100(default), 200, 500
    + 1学習のエピソード数 :  10(default),  20,  50

+ 結果
  + そこまで大きな影響は無さそう
  + 平均スコア, 平均step

    |           path|       average score|        average step|
    |---------------|--------------------|--------------------|
    |           base|  1000.00(    0.00) |     6.82(    3.70) |
    |      total_200|  1000.00(    0.00) |     7.62(    9.12) |
    |      total_500|   980.00(  140.00) |     8.20(   13.70) |
    |    episodes_20|   960.00(  195.96) |     8.58(   13.96) |
    |    episodes_50|  1000.00(    0.00) |     6.60(    3.18) |

## 現状まとめ
+ pybrainとmylib、ほぼ同等の結果となった.

+ 最初, この結果を出すために, backpropはパラメータを結構いじった.
  + が, 結局のところ, 学習係数が0.1では大きすぎて上手く学習できなかったぽい.
  + 0.02 - 0.05が良さそう.
  + ただ, 学習する内容によっても変わるかもしれない.

+ rpropを使っての結果があまり良くない.やり方間違ってる?




